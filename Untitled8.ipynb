{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgwNyjD+/HuOcrDG4ro62U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tagasu/training/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "2dZBlP-YItkv",
        "outputId": "4d9b597f-18f3-4e32-939c-176bc56faaa5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-534c77878ed4>\"\u001b[0;36m, line \u001b[0;32m117\u001b[0m\n\u001b[0;31m    plt.rcParams[\"figure.figsize\"] = (17.5, 7.5)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import tensorflow.keras \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "def Pressure_Data_CSV_to_Ndarray(CSV_Data):\n",
        " Ndarray_Data = np.loadtxt(CSV_Data, delimiter=',')  \n",
        " print(Ndarray_Data.shape)\n",
        " return Ndarray_Data\n",
        "\n",
        "\n",
        "p_0_data= Pressure_Data_CSV_to_Ndarray('p_wall.csv')\n",
        "p_8_data= Pressure_Data_CSV_to_Ndarray('p_11.csv')\n",
        "p_20_data= Pressure_Data_CSV_to_Ndarray('p_16.csv')\n",
        "p_36_data= Pressure_Data_CSV_to_Ndarray('p_20.csv')\n",
        "p_61_data= Pressure_Data_CSV_to_Ndarray('p_24.csv')\n",
        "p_96_data= Pressure_Data_CSV_to_Ndarray('p_28.csv')\n",
        "p_138_data= Pressure_Data_CSV_to_Ndarray('p_32.csv')\n",
        "\n",
        "\n",
        "pressure_data = np.concatenate([p_0_data, p_8_data, p_20_data, p_36_data, p_61_data, p_96_data, p_138_data], 0)\n",
        "print(pressure_data.shape)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test = train_test_split(pressure_data, test_size=0.2, shuffle=True, random_state=50)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "sv_data_0   = np.full((len(p_0_data)), 0)\n",
        "sv_data_8   = np.full((len(p_8_data)), 1)\n",
        "sv_data_20  = np.full((len(p_20_data)), 2)\n",
        "sv_data_36  = np.full((len(p_36_data)), 3)\n",
        "sv_data_61  = np.full((len(p_61_data)), 4)\n",
        "sv_data_96  = np.full((len(p_96_data)), 5)\n",
        "sv_data_138 = np.full((len(p_138_data)), 6)\n",
        "sv_data     = np.concatenate([sv_data_0, sv_data_8, sv_data_20, sv_data_36, sv_data_61, sv_data_96, sv_data_138], 0)\n",
        "print(sv_data.shape)\n",
        "print(sv_data)\n",
        "\n",
        "\n",
        "np_section = tensorflow.keras.utils.to_categorical(sv_data, 7)\n",
        "print(np_section.shape)\n",
        "print(np_section)\n",
        "\n",
        "\n",
        "y_train, y_test = train_test_split(np_section, test_size=0.2, shuffle=True, random_state=50)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "from keras.layers import Input, Dense, LeakyReLU\n",
        "from keras.models import Model, model_from_json\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "input_data = Input(shape=(4096))\n",
        "\n",
        "\n",
        "dense_1     = Dense(1024, activation=LeakyReLU())(input_data)\n",
        "dense_2     = Dense( 256, activation=LeakyReLU())(dense_1)\n",
        "dense_3     = Dense(  64, activation=LeakyReLU())(dense_2)\n",
        "output_data = Dense(   7, activation='sigmoid')(dense_3)\n",
        "\n",
        "\n",
        "classification_model = Model(input_data, output_data)\n",
        " \n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "classification_model.compile( optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "classification_model.summary()\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model( classification_model, to_file=\"model_img.png\")\n",
        "\n",
        "\n",
        "his = classification_model.fit(x_train, y_train,\n",
        "                               epochs = 50,\n",
        "                               batch_size = 50,\n",
        "                               shuffle=True,\n",
        "                               validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "json_string = classification_model.to_json()\n",
        "\n",
        "open('model.json', 'w').write(json_string)\n",
        "\n",
        "classification_model.save_weights('weights.h5')\n",
        "\n",
        "plt.plot(his.history['accuracy'],label=\"accuracy for training\")\n",
        "plt.plot(his.history['val_accuracy'],label=\"accuracy for validation\")\n",
        "plt.title('model accuracy', fontsize=20)\n",
        "plt.xlabel('epoch', fontsize=16)\n",
        "plt.ylabel('accuracy', fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "\n",
        "plt.plot(his.history['loss'],label=\"loss for training\")\n",
        "plt.plot(his.history['val_loss'],label=\"loss for validation\")\n",
        "plt.title('model loss', fontsize=20)\n",
        "plt.xlabel('epoch', fontsize=16)\n",
        "plt.ylabel('loss', fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "number = 18 \n",
        "\n",
        "\n",
        "def distribution(visu_data, visu_num):\n",
        "  visu_data_reshape = np.reshape(visu_data[visu_num], (64,64)) \n",
        "   plt.rcParams[\"figure.figsize\"] = (17.5, 7.5) \n",
        "  plt.pcolormesh(visu_data_reshape, cmap='jet', shading='gouraud') \n",
        "  plt.axes().set_aspect(0.375) \n",
        "  plt.xticks([0, 15, 31, 47], [ \"0\", \"2\", \"4\", \"6\"]) \n",
        "  plt.yticks([0, 19, 39, 59], [ \"0\", \"1\", \"2\", \"3\"]) \n",
        "  plt.xlabel('x/δ', fontsize=24) \n",
        "  plt.ylabel('z/δ', fontsize=24) \n",
        "  plt.tick_params(labelsize=16) \n",
        "  pp=plt.colorbar() \n",
        "  pp.set_label(\"Label\",  fontsize=2\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "distribution(x_test, number)\n",
        "\n",
        "pred_data = classification_model.predict(x_test) \n",
        "print(pred_data.shape)\n",
        " \n",
        "print('predict =',pred_data[number]) \n",
        "percent = pred_data[number].argmax() \n",
        "answer = y_test[number].argmax() \n",
        "rabel = ['wall', '8.83', '20.28', '36.34', '61.17', '96.00', '138.73'] \n",
        "print(\"Prediction is \", rabel[percent]) \n",
        "print(\"Anser is \", rabel[answer]) "
      ]
    }
  ]
}